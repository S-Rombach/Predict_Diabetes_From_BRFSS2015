{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hyperparameter optimization `no dia` vs (`pre`, `dia`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Init config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_orders = {\n",
    "    \"GenHlth\": [\"excellent\", \"very good\", \"good\", \"fair\", \"poor\"],\n",
    "    \"Age\": [\n",
    "        \"18-24\",\n",
    "        \"25-29\",\n",
    "        \"30-34\",\n",
    "        \"35-39\",\n",
    "        \"40-44\",\n",
    "        \"45-49\",\n",
    "        \"50-54\",\n",
    "        \"55-59\",\n",
    "        \"60-64\",\n",
    "        \"65-69\",\n",
    "        \"70-74\",\n",
    "        \"75-79\",\n",
    "        \"80+\",\n",
    "    ],\n",
    "    \"Education\": [\n",
    "        \"no school\",\n",
    "        \"elementary\",\n",
    "        \"some high school\",\n",
    "        \"high school graduate\",\n",
    "        \"college\",\n",
    "        \"college graduate\",\n",
    "    ],\n",
    "    \"Income\": [\"<$10k\", \"<$15k\", \"<$20k\", \"<$25k\", \"<$35k\", \"<$50k\", \"<$75k\", \">$75k\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from src.config import (\n",
    "    DATA_SPLIT_DIR,\n",
    "    TRAIN_RAW_FILENAME,\n",
    "    VALIDATION_RAW_FILENAME,\n",
    "    MODELS_DIR,\n",
    "    STUDY_DIR,\n",
    ")\n",
    "\n",
    "os.makedirs(STUDY_DIR, exist_ok=True)\n",
    "\n",
    "# For Bayesian Optimization\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# importing plotly and enable jupyter notebooks for showing optuna visualisations\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"iframe\"\n",
    "\n",
    "# for model comparison\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Load train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "df_train_raw = pd.read_csv(os.path.join(DATA_SPLIT_DIR, TRAIN_RAW_FILENAME))\n",
    "features_train_raw = df_train_raw.drop(\"Diabetes_012\", axis=1)\n",
    "target_train_raw = df_train_raw[\"Diabetes_012\"].replace({\"pre\": \"dia\"})\n",
    "\n",
    "\n",
    "df_val_raw = pd.read_csv(os.path.join(DATA_SPLIT_DIR, VALIDATION_RAW_FILENAME))\n",
    "features_val_raw = df_val_raw.drop(\"Diabetes_012\", axis=1)\n",
    "target_val_raw = df_val_raw[\"Diabetes_012\"].replace({\"pre\": \"dia\"})\n",
    "\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "target_train_enc = labelencoder.fit_transform(target_train_raw)\n",
    "target_val_enc = labelencoder.transform(target_val_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Custom Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingFlagTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        if hasattr(X, \"columns\"):\n",
    "            self.feature_names_in_ = list(X.columns)\n",
    "        else:\n",
    "            self.feature_names_in_ = list([f\"x{i}\" for i in range(X.shape[1])])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "\n",
    "        na_mask = (\n",
    "            pd.isna(X_).to_numpy() if isinstance(X_, pd.DataFrame) else np.isnan(X_)\n",
    "        )\n",
    "        return na_mask\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        if input_features is None:\n",
    "            input_features = self.feature_names_in_\n",
    "\n",
    "        output_features = [f\"{c}_isna\" for c in input_features]\n",
    "\n",
    "        return np.array(output_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoryFromThresholdTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, thresholds):\n",
    "        self.thresholds = thresholds\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.feature_names_in_ = list(X.columns)\n",
    "        else:\n",
    "            self.feature_names_in_ = list([f\"x{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "        if any(isinstance(t, list) for t in self.thresholds):\n",
    "            if not all(isinstance(t, list) for t in self.thresholds):\n",
    "                raise ValueError(\n",
    "                    \"'thresholds' must either be a list of skalars or a list of lists.\"\n",
    "                )\n",
    "            self.thresholds = [sorted(t) for t in self.thresholds]\n",
    "        else:\n",
    "            self.thresholds = [sorted(self.thresholds)]\n",
    "\n",
    "        if len(self.feature_names_in_) != len(self.thresholds):\n",
    "            raise ValueError(\n",
    "                \"number of input features and length of 'thresholds' must be the same.\"\n",
    "            )\n",
    "        return self\n",
    "\n",
    "    def _get_cat_from_threshold(self, value, thresholds):\n",
    "        if pd.isna(value):\n",
    "            return \"NA\"\n",
    "        if value >= thresholds[-1]:\n",
    "            result = f\"{thresholds[-1]}+\"\n",
    "        elif value < thresholds[0]:\n",
    "            result = f\"<{thresholds[0]}\"\n",
    "        else:\n",
    "            idx = next(i for i, val in list(enumerate(thresholds)) if val > value)\n",
    "\n",
    "            result = f\"[{thresholds[idx-1]}-{thresholds[idx]})\"\n",
    "        return result\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "\n",
    "        if isinstance(X_, pd.DataFrame):\n",
    "            X_ = X_.values\n",
    "\n",
    "        res = np.column_stack(\n",
    "            [\n",
    "                [self._get_cat_from_threshold(x, th) for x in X_[:, i]]\n",
    "                for i, th in enumerate(self.thresholds)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return res\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        if input_features is None:\n",
    "            input_features = self.feature_names_in_\n",
    "\n",
    "        return np.array([f\"{c}_cat\" for c in input_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "nominal_cols = [\n",
    "    \"HighBP\",\n",
    "    \"HighChol\",\n",
    "    \"CholCheck\",\n",
    "    \"Smoker\",\n",
    "    \"Stroke\",\n",
    "    \"HeartDiseaseorAttack\",\n",
    "    \"PhysActivity\",\n",
    "    \"Fruits\",\n",
    "    \"Veggies\",\n",
    "    \"HvyAlcoholConsump\",\n",
    "    \"AnyHealthcare\",\n",
    "    \"NoDocbcCost\",\n",
    "    \"DiffWalk\",\n",
    "    \"Sex\",\n",
    "]\n",
    "nominal_pipe = Pipeline(\n",
    "    [\n",
    "        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\n",
    "            \"ohe\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\", sparse_output=False),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ordinal_cols = [\"GenHlth\", \"Age\", \"Education\", \"Income\"]\n",
    "\n",
    "ordinal_categories = [ordinal_orders[col] for col in ordinal_cols]\n",
    "\n",
    "ordinal_pipe = Pipeline(\n",
    "    [\n",
    "        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encode\", OrdinalEncoder(categories=ordinal_categories)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "numeric_cols = []  # [\"MentHlth\", \"PhysHlth\"]  # \"BMI\",\n",
    "num_pipe = Pipeline(\n",
    "    [(\"impute\", SimpleImputer(strategy=\"median\")), (\"scale\", StandardScaler())]\n",
    ")\n",
    "\n",
    "missing_val_cols = numeric_cols + ordinal_cols + nominal_cols\n",
    "missing_val_pipe = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"flags\",\n",
    "            MissingFlagTransformer(),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "cat_gens = {\"BMI\": [20, 25, 30], \"MentHlth\": [0, 5, 10], \"PhysHlth\": [0, 5, 10]}\n",
    "cat_gen_cols = [\"BMI\", \"MentHlth\", \"PhysHlth\"]\n",
    "cat_gen_pipe = Pipeline(\n",
    "    [\n",
    "        (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "        (\n",
    "            \"cat_gen\",\n",
    "            CategoryFromThresholdTransformer([cat_gens[c] for c in cat_gen_cols]),\n",
    "        ),\n",
    "        (\n",
    "            \"ohe\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\", sparse_output=False),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, numeric_cols),\n",
    "        (\"ord\", ordinal_pipe, ordinal_cols),\n",
    "        (\"nom\", nominal_pipe, nominal_cols),\n",
    "        (\"miss\", missing_val_pipe, missing_val_cols),\n",
    "        (\"cg\", cat_gen_pipe, cat_gen_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "classifier = RandomForestClassifier(class_weight=\"balanced\", random_state=0)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\n",
    "            \"sample\",\n",
    "            RandomOverSampler(\n",
    "                random_state=5,\n",
    "            ),\n",
    "        ),\n",
    "        (\"clf\", RandomForestClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor.set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_gen_thresholds = [\n",
    "    (\n",
    "        \"cg_bmi_th\",\n",
    "        [\n",
    "            [30],\n",
    "            [20, 30],\n",
    "            [30, 45],\n",
    "            [20, 30, 40],\n",
    "            [20, 30, 40, 50],\n",
    "            [20, 30, 40, 50, 60],\n",
    "        ],\n",
    "    ),\n",
    "    (\"cg_mh_th\", [[0], [10], [0, 5], [0, 10, 20], [10, 20]]),\n",
    "    (\"cg_ph_th\", [[0], [10], [0, 5], [0, 10, 20], [10, 20]]),\n",
    "]\n",
    "\n",
    "cat_gen_thresholds = {\n",
    "    name: {\n",
    "        f\"[{','.join(sorted([str(x) for x in lst]))}]\": sorted(lst)\n",
    "        for lst in thresholds\n",
    "    }\n",
    "    for name, thresholds in cat_gen_thresholds\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Define study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_purpose = \"[\" + ','.join(sorted(list(target_train_raw.value_counts().index))) + \"]\"\n",
    "study_purpose = f\"rf,ros,{model_purpose}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Bayesian Optimization\n",
    "def objective(trial):\n",
    "    \"\"\"return maximized f1-score\"\"\"\n",
    "    \n",
    "    # search space\n",
    "    pipe_params = {\n",
    "        cg_name: trial.suggest_categorical(cg_name, choices=list(thresholds.keys()))\n",
    "        for cg_name, thresholds in cat_gen_thresholds.items()\n",
    "    }\n",
    "    pipeline.set_params(\n",
    "        preprocessor__cg__cat_gen__thresholds=[\n",
    "            cat_gen_thresholds[cg][cat] for cg, cat in pipe_params.items()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 310, step=20),\n",
    "        \"max_features\": trial.suggest_categorical(\n",
    "            \"max_features\", choices=['sqrt', 'log2']\n",
    "        ),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 60, step=5),\n",
    "        \"min_samples_split\": trial.suggest_int(\n",
    "            name=\"min_samples_split\", low=2, high=102, step=5\n",
    "        ),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\n",
    "            name=\"min_samples_leaf\", low=1, high=101, step=5\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # random forest classifier object\n",
    "    model_rf = RandomForestClassifier(\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        **params,\n",
    "    )\n",
    "\n",
    "    pipeline.named_steps[\"clf\"] = model_rf\n",
    "\n",
    "    # initiating cv\n",
    "    scores = cross_val_score(\n",
    "        estimator=pipeline,\n",
    "        X=features_train_raw,\n",
    "        y=target_train_enc,\n",
    "        scoring=\"f1_macro\",\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    scores = [score for score in scores if not np.isnan(score)]\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now()\n",
    "study_timestamp_str = timestamp.strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "study_name = f\"{study_timestamp_str}_{study_purpose}\"\n",
    "\n",
    "\n",
    "# create a study (aim to maximize score) und setting a seed (random_state) for reproduceability\n",
    "study = optuna.create_study(\n",
    "    sampler=TPESampler(seed=42),\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=f\"sqlite:///{os.path.join(STUDY_DIR, study_name)}.db\",\n",
    ")\n",
    "\n",
    "# perform hyperparamter tuning (while timing the process)\n",
    "time_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "study = optuna.load_study(\n",
    "    study_name=study_name,\n",
    "    storage=f\"sqlite:///{os.path.join(STUDY_DIR, study_name)}.db\"\n",
    ")\n",
    "study.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "#### Best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "import inspect\n",
    "\n",
    "classifier_init_params = inspect.signature(RandomForestClassifier.__init__).parameters\n",
    "best_params = study.best_params\n",
    "\n",
    "\n",
    "classifier = RandomForestClassifier(class_weight=\"balanced\", random_state=42, **{k:v for k,v in best_params.items() if k in classifier_init_params})\n",
    "\n",
    "pipeline.named_steps[\"clf\"] = classifier\n",
    "\n",
    "pipe_params = {k:v for k,v in best_params.items() if k not in classifier_init_params}\n",
    "pipeline.set_params(\n",
    "    preprocessor__cg__cat_gen__thresholds=[\n",
    "        cat_gen_thresholds[cg][cat] for cg, cat in pipe_params.items()\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.fit(features_train_raw, target_train_enc)\n",
    "\n",
    "model_timestamp = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_val_pred = pipeline.predict(features_val_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_features = \"RandomOverSampling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_evaluation import (\n",
    "    evaluate_classifier,\n",
    "    get_classification_report_from_results_as_df,\n",
    "    get_confusion_matrix_from_results_as_df,\n",
    ")\n",
    "\n",
    "target_val_pred_proba = None\n",
    "\n",
    "if hasattr(classifier, \"predict_proba\"):\n",
    "    target_val_pred_proba = pipeline.predict_proba(features_val_raw)\n",
    "\n",
    "    if target_train_raw.nunique() <= 2:\n",
    "        target_val_pred_proba = target_val_pred_proba[:, 1]\n",
    "\n",
    "\n",
    "results = evaluate_classifier(\n",
    "    classifier=classifier,\n",
    "    labels=list(labelencoder.classes_),\n",
    "    target_truth=target_val_raw,\n",
    "    target_pred=labelencoder.inverse_transform(target_val_pred),\n",
    "    target_pred_proba=target_val_pred_proba,\n",
    "    timestamp=model_timestamp,\n",
    "    model_purpose=model_purpose,\n",
    "    special_features=special_features,\n",
    ")\n",
    "\n",
    "print(\"precision:\", results[\"precision\"])\n",
    "print(\"F1:\", results[\"f1\"])\n",
    "print(\"bal acc:\", results[\"bal_accuracy\"])\n",
    "print(\"roc auc:\", results[\"roc_auc_score\"])\n",
    "\n",
    "print()\n",
    "print(\"confusion_matrix\")\n",
    "display(get_confusion_matrix_from_results_as_df(results))\n",
    "\n",
    "print()\n",
    "print(\"classification_report\")\n",
    "display(get_classification_report_from_results_as_df(results))\n",
    "\n",
    "\n",
    "labels = results[\"predicts\"]\n",
    "model_name = results[\"model_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Save the model and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "folder = os.path.join(MODELS_DIR, model_name)\n",
    "filename = os.path.join(folder, model_name)\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "with open(f\"{filename}.model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(classifier, f)\n",
    "\n",
    "with open(f\"{filename}.pipeline.pkl\", \"wb\") as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "with open(f\"{filename}.label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(labelencoder, f)\n",
    "\n",
    "with open(f\"{filename}.model.txt\", \"w\") as file:\n",
    "    file.write(str(classifier))\n",
    "\n",
    "with open(f\"{filename}.results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "with open(f\"{filename}.pipeline_params.txt\", \"w\") as f:\n",
    "    f.write(preprocessor.get_params().__str__())\n",
    "\n",
    "with open(f\"{filename}.model_params.json\", \"w\") as f:\n",
    "    json.dump(classifier.get_params(), f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scoring_mode = \"f1_macro\"\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    estimator=pipeline,\n",
    "    X=features_train_raw,\n",
    "    y=target_train_enc,\n",
    "    cv=5,\n",
    "    scoring=scoring_mode,\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    ")\n",
    "\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "\n",
    "df_lc = pd.DataFrame({\"train_sizes\": train_sizes, \"train_scores\": train_mean, \"val_scores\": val_mean})\n",
    "df_lc.to_csv(f\"{filename}.learning_curves.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import uniform_filter1d\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "\n",
    "# Hauptlinien\n",
    "(train_line,) = ax.plot(train_sizes, train_mean, label=\"Training score\")\n",
    "(val_line,) = ax.plot(train_sizes, val_mean, label=\"Validation score\")\n",
    "\n",
    "# Farben extrahieren\n",
    "train_color = train_line.get_color()\n",
    "val_color = val_line.get_color()\n",
    "\n",
    "# Min-/Max-Werte\n",
    "y_lines_min = [train_mean.min(), val_mean.min()]\n",
    "y_lines_max = [train_mean.max(), val_mean.max()]\n",
    "\n",
    "# Hilfslinien\n",
    "for y in y_lines_min:\n",
    "    ax.axhline(y, color=\"red\", linestyle=\"--\", linewidth=0.8, alpha=0.2)\n",
    "for y in y_lines_max:\n",
    "    ax.axhline(y, color=\"green\", linestyle=\"--\", linewidth=0.8, alpha=0.2)\n",
    "\n",
    "# Rollender Durchschnitt (Fenstergröße = 3)\n",
    "train_rolling = uniform_filter1d(train_mean, size=3, mode=\"nearest\")\n",
    "val_rolling = uniform_filter1d(val_mean, size=3, mode=\"nearest\")\n",
    "\n",
    "ax.plot(\n",
    "    train_sizes,\n",
    "    train_rolling,\n",
    "    label=\"Train rolling avg\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=1.5,\n",
    "    color=train_color,\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.plot(\n",
    "    train_sizes,\n",
    "    val_rolling,\n",
    "    label=\"Val rolling avg\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=1.5,\n",
    "    color=val_color,\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "# y-Ticks\n",
    "yticks = sorted(set(ax.get_yticks().tolist() + y_lines_min + y_lines_max))\n",
    "ax.set_yticks(yticks)\n",
    "\n",
    "ax.set_xlabel(\"Training set size\")\n",
    "ax.set_ylabel(scoring_mode.replace(\"_\", \" \").capitalize())\n",
    "\n",
    "ax.set_title(f\"Learning curve for model '{results[\"timestamp\"]}'\")\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{filename}.learning_curve_img.png\", format=\"png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "target_train_pred = classifier.predict(preprocessor.transform(features_train_raw))\n",
    "\n",
    "f1_base = f1_score(target_train_enc, target_train_pred, average=\"weighted\")\n",
    "\n",
    "importances_of_permutations = []\n",
    "for feat in features_train_raw.columns:\n",
    "    features_permutated = features_train_raw.copy()\n",
    "\n",
    "    permutation_run_scores = []\n",
    "    for i in range(5):\n",
    "        series_perm = features_permutated[feat].sample(\n",
    "            frac=1, replace=False, random_state=0\n",
    "        )\n",
    "        series_perm.reset_index(drop=True, inplace=True)\n",
    "        features_permutated[feat] = series_perm\n",
    "\n",
    "        preprocessed_features_permutated = preprocessor.transform(features_permutated)\n",
    "        f1_permutated = f1_score(\n",
    "            target_train_enc,\n",
    "            classifier.predict(preprocessed_features_permutated),\n",
    "            average=\"weighted\",\n",
    "        )\n",
    "        permutation_run_scores.append(f1_base - f1_permutated)\n",
    "\n",
    "    importances_of_permutations.append(np.mean(permutation_run_scores))\n",
    "\n",
    "feature_importances = pd.Series(\n",
    "    data=importances_of_permutations, index=features_train_raw.columns\n",
    ")\n",
    "feature_importances.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "with open(f\"{filename}.feature_importances.json\", \"w\") as f:\n",
    "    json.dump(feature_importances.to_dict(), f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 0.3 * len(features_val_raw.columns)))\n",
    "sns.barplot(x=feature_importances.values, y=feature_importances.index, ax=ax)\n",
    "ax.set_title(f\"feature importances for model '{model_name}'\")\n",
    "for i, (val, label) in enumerate(\n",
    "    zip(feature_importances.values, feature_importances.index)\n",
    "):\n",
    "    ax.text(val, i, f\" {val:.4f}\", va=\"center\", ha=\"left\", fontsize=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{filename}.feature_importances.png\", format=\"png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## Optuna Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_optimization_history(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### Parallel coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "### Parameter importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predict-diabetes-from-brfss2015",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
